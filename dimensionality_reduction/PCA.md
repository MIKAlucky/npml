在PCA中，我们要做的是找到一个方向向量，当我们把所有的数据都投射到该向量上时，我们希望投射平均均方误差尽可能小。而投射误差是从特征向量向该方向向量作垂线的长度。


**问题描述**:

要将$n$维数据降至$k$维，目标是找到向量$u^{(1)},u^{(2)},...,u^{(k)}$使得总的投射误差最小。



**算法流程**:

PCA减少$n$维到$k$维

1、均值归一化。计算出所有特征的均值，然后令$x_j=x_j-\mu_J$。如果特征在不同的数量级上，我们还需要除以方差$\sigma^2$

2、计算协方差矩阵$Sigma=\frac 1 m \sum_{i=1}^n(x^{(i)})(x^{(i)})^T$

3、计算协方差矩阵$Sigma$的特征向量

\[U, S, V\] = svd($Sigma$)

对于一个$n*n$维度的矩阵，上式中的$U$是一个具有与数据之间最小投射误差的方向向量构成的矩阵。$n$维降至$k$维，我们只需从$U$中选择前$k$个向量，获得一个$n*k$的矩阵$U_{reduce}$，新的特征向量$z^{(i)}=U^{T}_{reduce}*x^{(i)}$ <!--*-->



其中$x$是$n*1$维的，因此结果是$k*1$维的。


其中的S是一个n×n的矩阵，只有对角线上有值，而其它单元都是0，我们可以使用这个矩阵来计算平均均方误差与训练集方差的比例： $$\dfrac {\dfrac {1}{m}\sum^{m}{i=1}\left| x^{\left( i\right) }-x^{\left( i\right) }{approx}\right| ^{2}}{\dfrac {1}{m}\sum^{m}{i=1}\left| x^{(i)}\right| ^{2}}=1-\dfrac {\Sigma^{k}{i=1}S_{ii}}{\Sigma^{m}{i=1}S{ii}}\leq 1%$$

也就是：$$\frac {\Sigma^{k}{i=1}s{ii}}{\Sigma^{n}{i=1}s{ii}}\geq0.99$$

在压缩过数据后，我们可以采用如下方法来近似地获得原有的特征：$$x^{\left( i\right) }{approx}=U{reduce}·z^{(i)}$$

